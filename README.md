بررسی کلی کدها
مقاله شما به پیاده‌سازی یک سیستم یادگیری فدرال (Federated Learning) برای پیش‌بینی حملات سایبری DDoS با استفاده از یک مدل زبانی بزرگ تقطیرشده (DistilBERT) پرداخته است. این سیستم شامل دو کلاینت (client1 و client2) و یک سرور است که مدل‌های محلی را جمع‌آوری و تجمیع می‌کند. در ادامه، اجزای اصلی سیستم و عملکرد آن‌ها رو تحلیل می‌کنم:

معماری سیستم:

کلاینت‌ها: هر کلاینت داده‌های خود را از دیتاست CICIDS2017.csv پیش‌پردازش می‌کند، ویژگی‌های شبکه‌ای (مانند پورت مقصد، مدت‌زمان جریان، تعداد بسته‌ها و غیره) را به متن تبدیل می‌کند، و از DistilBERT برای یادگیری و پیش‌بینی حملات DDoS استفاده می‌کند. هر کلاینت مدل محلی خود را آموزش می‌دهد و سپس وزن‌های مدل را به سرور ارسال می‌کند.
سرور: سرور وزن‌های مدل‌های محلی را از کلاینت‌ها دریافت می‌کند، آن‌ها را با استفاده از میانگین‌گیری ساده (Federated Averaging) تجمیع می‌کند و مدل تجمیع‌شده را به کلاینت‌ها بازمی‌گرداند.
مدل: مدل DDoSClassifier از DistilBERT به‌عنوان پایه استفاده می‌کند و یک لایه خطی برای طبقه‌بندی باینری (DDoS یا غیر DDoS) به آن اضافه شده است.


پیش‌پردازش داده:

داده‌ها از دیتاست CICIDS2017 استخراج شده و تنها 10٪ از داده‌ها (data_fraction_size=0.1) برای کاهش زمان محاسبات استفاده شده است.
ویژگی‌های شبکه‌ای به متن‌های توصیفی تبدیل شده‌اند تا برای ورودی DistilBERT مناسب باشند.
داده‌ها به سه مجموعه آموزشی، اعتبارسنجی و تست تقسیم شده‌اند (60٪ آموزش، 20٪ اعتبارسنجی، 20٪ تست).


ارزیابی مدل:

معیارهای ارزیابی شامل دقت (Accuracy)، خطا (Loss)، دقت مثبت (Precision)، یادآوری (Recall)، و F1-Score هستند.
هر کلاینت مدل محلی و مدل تجمیع‌شده را ارزیابی می‌کند و نتایج را ذخیره می‌کند. همچنین، نمودارهایی مانند ماتریس درهم‌ریختگی (Confusion Matrix) و مقایسه متریک‌ها تولید می‌شود.


ارتباطات شبکه:

کلاینت‌ها و سرور از سوکت‌های TCP برای انتقال وزن‌های مدل استفاده می‌کنند. داده‌ها با استفاده از فشرده‌سازی gzip منتقل می‌شوند تا حجم انتقال کاهش یابد.
سرور از threading برای مدیریت چندین کلاینت به‌صورت همزمان استفاده می‌کند.




تحلیل نتایج
بر اساس فایل‌های متریک و خروجی‌های ترمینال، نتایج عملکرد مدل‌های محلی و تجمیع‌شده برای کلاینت‌ها به شرح زیر است:
کلاینت 1:

مدل محلی (client1_local_metrics.csv):

Accuracy: 99.09%
Loss: 0.0253
Precision: 0.9844
Recall: 1.0
F1-Score: 0.9921


مدل تجمیع‌شده (client1_aggregated_metrics.csv):

Accuracy: 99.93%
Loss: 0.0028
Precision: 1.0
Recall: 0.9988
F1-Score: 0.9994



کلاینت 2:

مدل محلی (client2_local_metrics.csv):

Accuracy: 99.05%
Loss: 0.0256
Precision: 0.9836
Recall: 1.0
F1-Score: 0.9917


مدل تجمیع‌شده (client2_aggregated_metrics.csv):

Accuracy: 99.87%
Loss: 0.0058
Precision: 0.9988
Recall: 0.9988
F1-Score: 0.9988



تحلیل مقایسه‌ای:

بهبود عملکرد با تجمیع: در هر دو کلاینت، مدل تجمیع‌شده (Aggregated Model) نسبت به مدل محلی عملکرد بهتری دارد:

دقت (Accuracy): در کلاینت 1 از 99.09% به 99.93% و در کلاینت 2 از 99.05% به 99.87% افزایش یافته است.
خطا (Loss): خطا به‌طور قابل‌توجهی کاهش یافته است (از 0.0253 به 0.0028 در کلاینت 1 و از 0.0256 به 0.0058 در کلاینت 2).
Precision و F1-Score: در هر دو کلاینت، این معیارها در مدل تجمیع‌شده بهبود یافته‌اند و به مقادیر نزدیک به 1 رسیده‌اند.
Recall: در کلاینت 1 اندکی کاهش یافته (از 1.0 به 0.9988)، اما همچنان بسیار بالاست.


زمان‌بندی:

آموزش مدل محلی در هر کلاینت حدود 16-17 دقیقه طول کشیده است (3 эпох با سرعت تقریبی 2.5 بچ در ثانیه).
انتقال مدل‌ها به سرور و دریافت مدل تجمیع‌شده سریع (حدود 10-20 ثانیه) بوده است، که نشان‌دهنده کارایی فشرده‌سازی و انتقال داده‌هاست.
کل فرآیند (آموزش، انتقال، تجمیع، و ارزیابی) برای هر کلاینت حدود 19-20 دقیقه طول کشیده است.



مشاهدات از خروجی ترمینال:

کلاینت 1:

آموزش مدل محلی با میانگین خطای کاهشی (از 0.0721 به 0.0055 در 3 эпох) انجام شده است.
ارزیابی مدل محلی و تجمیع‌شده با موفقیت انجام شده و نمودارهای مقایسه‌ای تولید شده‌اند.
انتقال مدل به سرور و دریافت مدل تجمیع‌شده بدون خطا انجام شده است.


کلاینت 2:

مشابه کلاینت 1، آموزش با کاهش خطا (از 0.0491 به 0.0043) انجام شده است.
ارزیابی و تولید نمودارها موفقیت‌آمیز بوده است.
انتقال و دریافت مدل‌ها بدون مشکل انجام شده است.


سرور:

سرور مدل‌های هر دو کلاینت را با موفقیت دریافت کرده و تجمیع کرده است.
در ارسال مدل تجمیع‌شده به کلاینت‌ها، دو خطای [WinError 10053] (اتصال توسط نرم‌افزار میزبان قطع شده) رخ داده است، اما سرور با تلاش مجدد (Retry) موفق به ارسال مدل به هر دو کلاینت شده است.




نقاط قوت

عملکرد بالای مدل:

دقت بسیار بالای مدل‌ها (بالای 99%) نشان‌دهنده کارایی بالای DistilBERT در طبقه‌بندی حملات DDoS است.
بهبود قابل‌توجه عملکرد در مدل تجمیع‌شده نشان می‌دهد که یادگیری فدرال به‌خوبی عمل کرده و ترکیب دانش محلی کلاینت‌ها منجر به مدل قوی‌تری شده است.


کارایی یادگیری فدرال:

استفاده از میانگین‌گیری ساده (Federated Averaging) برای تجمیع مدل‌ها روشی مؤثر و سبک بوده که نتایج خوبی به همراه داشته است.
فشرده‌سازی داده‌ها با gzip و انتقال چانک‌شده (chunked) باعث کاهش زمان انتقال مدل‌ها شده است.


پیاده‌سازی قوی:

کدها ساختار منظمی دارند و از کتابخانه‌های استاندارد مانند PyTorch، Transformers، و scikit-learn استفاده شده است.
استفاده از tqdm برای نمایش پیشرفت و ثبت زمان‌بندی‌ها (logging) به شفافیت فرآیند کمک کرده است.
تولید نمودارهای بصری (مانند ماتریس درهم‌ریختگی و مقایسه متریک‌ها) برای تحلیل نتایج بسیار مفید است.


مدیریت خطاها:

سیستم با استفاده از مکانیزم‌های retry و timeout در برابر خطاهای شبکه (مانند [WinError 10053]) مقاوم است.
بررسی وجود مسیرهای فایل و مدیریت خطاهای احتمالی در کدها به‌خوبی انجام شده است.
